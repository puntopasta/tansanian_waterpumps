{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction year experimentation\n",
    "In this notebook we try a number of solutions for dealing with the missing age values. This way we select a good  solution. We only use the TRAINING SET here, where we create a nested train test split within the global training set to do this validation on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import data_loading, warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try a model fit leaving in the missing construction year entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 17662, 2: 12528, 1: 2203})\n",
      "Label distribution in testing set:  Counter({0: 5857, 2: 4222, 1: 719})\n",
      "[[4015    0 1842]\n",
      " [ 439    0  280]\n",
      " [2799    0 1423]]\n",
      "Accuracy score:  0.5036117799592517\n",
      "Cohen kappa:  0.021500163155778407\n"
     ]
    }
   ],
   "source": [
    "data = data_loading.load_dataset(data_folder='../data')\n",
    "data = data_loading.data_cleaning(data)\n",
    "data = data_loading.numeric_groundtruth(data)\n",
    "\n",
    "train_df, _ = data_loading.split_data(data)\n",
    "train_df, test_df = data_loading.split_data(train_df) # split up training data into two net sets.\n",
    "\n",
    "x_train = np.expand_dims(train_df.construction_year.as_matrix(),1)\n",
    "y_train = np.expand_dims(train_df.status_group.as_matrix(),1)\n",
    "\n",
    "x_test = np.expand_dims(test_df.construction_year.as_matrix(),1)\n",
    "y_test = np.expand_dims(test_df.status_group.as_matrix(),1)\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('Accuracy score: ', accuracy_score(y_test,pred))\n",
    "print('Cohen kappa: ', cohen_kappa_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try again after removing the missing construction year entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 12263, 2: 8123, 1: 1400})\n",
      "Label distribution in testing set:  Counter({0: 4002, 2: 2784, 1: 477})\n",
      "[[2726  320  956]\n",
      " [ 255   66  156]\n",
      " [1176  261 1347]]\n",
      "Accuracy score:  0.5698747074211759\n",
      "Cohen kappa:  0.21652920300078948\n"
     ]
    }
   ],
   "source": [
    "data = data_loading.load_dataset(data_folder='../data')\n",
    "data = data_loading.data_cleaning(data)\n",
    "data = data_loading.numeric_groundtruth(data)\n",
    "\n",
    "train_df, _ = data_loading.split_data(data)\n",
    "train_df = train_df[train_df.construction_year != 0]\n",
    "\n",
    "train_df, test_df = data_loading.split_data(train_df) # split up training data into two net sets.\n",
    "\n",
    "x_train = np.expand_dims(train_df.construction_year.as_matrix(),1)\n",
    "y_train = np.expand_dims(train_df.status_group.as_matrix(),1)\n",
    "\n",
    "x_test = np.expand_dims(test_df.construction_year.as_matrix(),1)\n",
    "y_test = np.expand_dims(test_df.status_group.as_matrix(),1)\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('Accuracy score: ', accuracy_score(y_test,pred))\n",
    "print('Cohen kappa: ', cohen_kappa_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clearly a linear model gets confused when construction years are 0.  However we cannot just drop them since these entries make up a significant portion of the data. Let's try to fill in the mean year (to minimise the effect of this feature when its value is missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 17662, 2: 12528, 1: 2203})\n",
      "Label distribution in testing set:  Counter({0: 5857, 2: 4222, 1: 719})\n",
      "[[2751 2067 1039]\n",
      " [ 229  311  179]\n",
      " [1178 1608 1436]]\n",
      "Accuracy score:  0.4165586219670309\n",
      "Cohen kappa:  0.1297758811576626\n"
     ]
    }
   ],
   "source": [
    "data = data_loading.load_dataset(data_folder='../data')\n",
    "data = data_loading.data_cleaning(data)\n",
    "data = data_loading.numeric_groundtruth(data)\n",
    "\n",
    "valid_year_data = data[data.construction_year != 0]\n",
    "mean_year = np.int(valid_year_data.construction_year.mean())\n",
    "data.construction_year[data.construction_year == 0] = mean_year\n",
    "\n",
    "train_df, _ = data_loading.split_data(data)\n",
    "\n",
    "train_df, test_df = data_loading.split_data(train_df) # split up training data into two net sets.\n",
    "\n",
    "x_train = np.expand_dims(train_df.construction_year.as_matrix(),1)\n",
    "y_train = np.expand_dims(train_df.status_group.as_matrix(),1)\n",
    "\n",
    "x_test = np.expand_dims(test_df.construction_year.as_matrix(),1)\n",
    "y_test = np.expand_dims(test_df.status_group.as_matrix(),1)\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('Accuracy score: ', accuracy_score(y_test,pred))\n",
    "print('Cohen kappa: ', cohen_kappa_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try setting the minimum year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 17662, 2: 12528, 1: 2203})\n",
      "Label distribution in testing set:  Counter({0: 5857, 2: 4222, 1: 719})\n",
      "[[3429  166 2262]\n",
      " [ 320   25  374]\n",
      " [1773  223 2226]]\n",
      "Accuracy score:  0.5260233376551213\n",
      "Cohen kappa:  0.12872979131765672\n"
     ]
    }
   ],
   "source": [
    "data = data_loading.load_dataset(data_folder='../data')\n",
    "data = data_loading.data_cleaning(data)\n",
    "data = data_loading.numeric_groundtruth(data)\n",
    "\n",
    "valid_year_data = data[data.construction_year != 0]\n",
    "min_year = np.int(valid_year_data.construction_year.min())\n",
    "data.construction_year[data.construction_year == 0] = min_year\n",
    "\n",
    "train_df, _ = data_loading.split_data(data)\n",
    "\n",
    "train_df, test_df = data_loading.split_data(train_df) # split up training data into two net sets.\n",
    "\n",
    "x_train = np.expand_dims(train_df.construction_year.as_matrix(),1)\n",
    "y_train = np.expand_dims(train_df.status_group.as_matrix(),1)\n",
    "\n",
    "x_test = np.expand_dims(test_df.construction_year.as_matrix(),1)\n",
    "y_test = np.expand_dims(test_df.status_group.as_matrix(),1)\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('Accuracy score: ', accuracy_score(y_test,pred))\n",
    "print('Cohen kappa: ', cohen_kappa_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems like we can only slightly improve Cohen's kappa and accuracy in comparison to keeping the 0 values in.\n",
    "\n",
    "\n",
    "### Next, let's see whether it adds value to look at the age (construction year relative to the recording date) of the pump during measurement. This is likely because the measurements have been taken over several decades and thus the construction year by itself does not tell us anything about the age. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 17662, 2: 12528, 1: 2203})\n",
      "Label distribution in testing set:  Counter({0: 5857, 2: 4222, 1: 719})\n",
      "[[4175  838  844]\n",
      " [ 475   89  155]\n",
      " [2421  555 1246]]\n",
      "Accuracy score:  0.5102796814224857\n",
      "Cohen kappa:  0.11662155311745437\n"
     ]
    }
   ],
   "source": [
    "data = data_loading.load_dataset(data_folder='../data')\n",
    "data = data_loading.data_cleaning(data)\n",
    "data = data_loading.numeric_groundtruth(data)\n",
    "\n",
    "data.date_recorded = [x.year for x in data.date_recorded.astype('datetime64')]\n",
    "valid_year_data = data[data.construction_year != 0]\n",
    "min_year = np.int(valid_year_data.construction_year.mean())\n",
    "max_age = np.int(np.mean(valid_year_data.date_recorded - valid_year_data.construction_year))\n",
    "\n",
    "data['age_at_measurement'] = data.date_recorded - data.construction_year\n",
    "data['age_at_measurement'][data.construction_year == 0] = max_age\n",
    "data.construction_year[data.construction_year == 0] = min_year\n",
    "\n",
    "train_df, _ = data_loading.split_data(data)\n",
    "\n",
    "train_df, test_df = data_loading.split_data(train_df) # split up training data into two net sets.\n",
    "\n",
    "x_train = train_df[['age_at_measurement','construction_year']].as_matrix()\n",
    "y_train = np.expand_dims(train_df.status_group.as_matrix(),1)\n",
    "\n",
    "x_test = test_df[['age_at_measurement','construction_year']].as_matrix()\n",
    "y_test = np.expand_dims(test_df.status_group.as_matrix(),1)\n",
    "\n",
    "lr = LogisticRegression(class_weight='balanced', multi_class='multinomial', solver='newton-cg')\n",
    "lr.fit(x_train,y_train)\n",
    "pred = lr.predict(x_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('Accuracy score: ', accuracy_score(y_test,pred))\n",
    "print('Cohen kappa: ', cohen_kappa_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doesn't seem to add much..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdr",
   "language": "python",
   "name": "bdr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
