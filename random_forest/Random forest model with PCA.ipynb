{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Model with PCA\n",
    "In this notebook we transform categorical features to one-hot encoding and then perform PCA (so-called matrix factorisation) to come up with meaningful numeric representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(test_x,test_y, rfc):\n",
    "    pred = rfc.predict(test_x)\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "\n",
    "    print(confusion_matrix(test_y,pred))\n",
    "    print('Acc: ',accuracy_score(test_y,pred))\n",
    "    print('Kappa: ',cohen_kappa_score(test_y,pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\n",
    "\n",
    "    E.g. for use with categorical_crossentropy.\n",
    "\n",
    "    # Arguments\n",
    "        y: class vector to be converted into a matrix\n",
    "            (integers from 0 to num_classes).\n",
    "        num_classes: total number of classes.\n",
    "\n",
    "    # Returns\n",
    "        A binary matrix representation of the input.\n",
    "    \"\"\"\n",
    "    y = np.array(y, dtype='int').ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    return categorical\n",
    "\n",
    "def categorical_factorisation(data, test_data):\n",
    "    '''\n",
    "    User matrix factorisation to arrive at numerical representation that captures most variance.\n",
    "    :param data: data\n",
    "    :return: data, with principal component representation of each categorical feature.\n",
    "    '''\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    for feature in data.columns:\n",
    "        if data[feature].dtype == 'O':\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            le.fit(data[feature])\n",
    "            num = le.transform(data[feature])\n",
    "            one_hot = to_categorical(num)\n",
    "            arity = one_hot.shape[-1]\n",
    "            if arity > 100:\n",
    "                continue\n",
    "            max_components = int(np.min([10, np.ceil(arity/2)]))\n",
    "            pca = PCA(n_components=max_components)\n",
    "            components = pca.fit_transform(one_hot)\n",
    "            component_names = ['{f}_{i}'.format(f=feature, i=i) for i in range(max_components)]\n",
    "            new_features = pd.DataFrame(data=components, columns=component_names, index=data.index)\n",
    "            data = pd.concat([data,new_features],axis=1)\n",
    "            \n",
    "            # now do the same for the test data, but re-apply the components from training.\n",
    "            num = le.transform(test_data[feature])\n",
    "            one_hot = to_categorical(num)\n",
    "            components = pca.transform(one_hot)\n",
    "            new_features = pd.DataFrame(data=components, columns=component_names, index=test_data.index)\n",
    "            test_data = pd.concat([test_data,new_features],axis=1)\n",
    "    return data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features = [\n",
    "    'gps_height',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'population',\n",
    "    'amount_tsh',\n",
    "    'age_at_measurement',\n",
    "    'payment_type',\n",
    "    'management_group',\n",
    "    'quality_group',\n",
    "    'region',\n",
    "    'basin',\n",
    "    'extraction_type_class',\n",
    "    'quantity_group',\n",
    "    'waterpoint_type_group',\n",
    "    'source_type',\n",
    "    'source_class'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.12 GiB for an array with shape (43191, 28347) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-6fe8aee8aaf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loading_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselected_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcategorical_factorisation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-eb241672a906>\u001b[0m in \u001b[0;36mcategorical_factorisation\u001b[0;34m(data, test_data)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mone_hot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0marity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marity\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-eb241672a906>\u001b[0m in \u001b[0;36mto_categorical\u001b[0;34m(y, num_classes)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mcategorical\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcategorical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 9.12 GiB for an array with shape (43191, 28347) and data type float64"
     ]
    }
   ],
   "source": [
    "from data_loading import data_loading_pipeline\n",
    "train_df, test_df = data_loading_pipeline('../data', selected_features = None)\n",
    "\n",
    "train_df, test_df = categorical_factorisation(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_numeric_features = [c for c in train_df.columns if (train_df[c].dtype != 'O') and c != 'status_group']\n",
    "\n",
    "train_x = train_df[all_numeric_features]\n",
    "test_x = test_df[all_numeric_features]\n",
    "\n",
    "train_y = train_df.status_group.as_matrix()\n",
    "test_y = test_df.status_group.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use random forests to optimise the feature set using cross-validated recursive feature elimination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features : 24\n"
     ]
    }
   ],
   "source": [
    "algo = RandomForestClassifier(n_estimators=100)\n",
    "selector = RFE(estimator=algo)\n",
    "\n",
    "selector.fit(train_x, train_y)\n",
    "\n",
    "print(\"Optimal number of features : %d\" % selector.n_features_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features: \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 96 but corresponding boolean dimension is 48",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-a1d0260c4997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Selected features: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_numeric_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n\\nDiscarded features: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_numeric_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 96 but corresponding boolean dimension is 48"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print('Selected features: ')\n",
    "print(np.array(all_numeric_features)[[s for s in selector.get_support()]])\n",
    "print('\\n\\nDiscarded features: ')\n",
    "print(np.array(all_numeric_features)[[not s for s in selector.get_support()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = train_x[train_x.columns[selector.get_support()]]\n",
    "test_x = test_x[test_x.columns[selector.get_support()]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit a large random forest classifier on selected features and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6861  237  772]\n",
      " [ 497  332  180]\n",
      " [1064  109 4345]]\n",
      "Acc:  0.8014169618670557\n",
      "Kappa:  0.6294454402625664\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "initial_model = RandomForestClassifier(n_estimators=1000, n_jobs=4)\n",
    "initial_model.fit(train_x, train_y)\n",
    "eval_model(test_x,test_y, initial_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balancing for minority class by automatically adjusting  class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6876  229  765]\n",
      " [ 503  321  185]\n",
      " [1071  100 4347]]\n",
      "Acc:  0.8018337153573661\n",
      "Kappa:  0.6295824756954155\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=4,class_weight='balanced')\n",
    "rfc.fit(train_x, train_y)\n",
    "eval_model(test_x,test_y, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Undersampling the majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1921 4980  969]\n",
      " [  57  903   49]\n",
      " [ 187 2912 2419]]\n",
      "Acc:  0.36417309161630895\n",
      "Kappa:  0.18846207461685305\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "cc = ClusterCentroids(random_state=0)\n",
    "X_resampled, y_resampled = cc.fit_sample(train_x, train_y)\n",
    "\n",
    "np.random.seed(42)\n",
    "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=4)\n",
    "\n",
    "rfc.fit(X_resampled, y_resampled)\n",
    "eval_model(test_x,test_y, rfc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minority class over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6628  445  797]\n",
      " [ 416  416  177]\n",
      " [1000  166 4352]]\n",
      "Acc:  0.7915537959297075\n",
      "Kappa:  0.6194772503034951\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(n_jobs=4,k_neighbors=5)\n",
    "train_x_smote, train_y_smote = smote.fit_sample(train_x,train_y)\n",
    "\n",
    "np.random.seed(42)\n",
    "rfc = RandomForestClassifier(n_estimators=1000, n_jobs=4)\n",
    "\n",
    "rfc.fit(train_x_smote, train_y_smote)\n",
    "eval_model(test_x,test_y, rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
