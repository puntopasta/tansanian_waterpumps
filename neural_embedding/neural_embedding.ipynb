{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural embedding model\n",
    "Since we are not very satisfied with the ad-hoc re-mapping of categorical variables to arbitrary numbers, we propose a more novel solution here where we use embedding layers to find optimal numeric representations for categorical variables with respect to the prediction task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_features_numeric = [\n",
    "    'gps_height',\n",
    "    'latitude',\n",
    "    'longitude',\n",
    "    'population',\n",
    "    'amount_tsh',\n",
    "    'construction_year',\n",
    "]\n",
    "\n",
    "selected_features_categorical = [\n",
    "    'payment_type',\n",
    "    'management_group',\n",
    "    'quality_group',\n",
    "    'region',\n",
    "    'basin',\n",
    "    'extraction_type_class',\n",
    "    'quantity_group',\n",
    "    'waterpoint_type_group',\n",
    "    'source_type',\n",
    "    'source_class'\n",
    "]\n",
    "\n",
    "all_features =  selected_features_categorical + selected_features_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training set:  Counter({0: 23519, 2: 16750, 1: 2922})\n",
      "Label distribution in testing set:  Counter({0: 7870, 2: 5518, 1: 1009})\n",
      "Label distribution in training set:  Counter({0: 17662, 2: 12528, 1: 2203})\n",
      "Label distribution in testing set:  Counter({0: 5857, 2: 4222, 1: 719})\n"
     ]
    }
   ],
   "source": [
    "from data_loading import data_loading_pipeline, split_data\n",
    "experimentation_df, holdout_df = data_loading_pipeline('../data')\n",
    "train_df, test_df = split_data(experimentation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First prepare the data for the model by one-hot encoding all categorical inputs and merging all numeric inputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "def prepare_inputs(df):\n",
    "    inputs = {}\n",
    "    for f in selected_features_categorical:\n",
    "        inputs[f] = to_categorical(df[f])\n",
    "\n",
    "    inputs['continuous'] = df[selected_features_numeric].as_matrix()\n",
    "    return inputs\n",
    "\n",
    "smote = False\n",
    "if smote:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote = SMOTE(n_jobs=4,k=5)\n",
    "    train_x_smote, train_y_smote = smote.fit_sample(train_df[all_features],train_df.status_group)\n",
    "\n",
    "    train_inputs = prepare_inputs(pd.DataFrame(train_x_smote,columns=all_features))\n",
    "    test_inputs = prepare_inputs(test_df)\n",
    "\n",
    "    train_output= to_categorical(train_y_smote)\n",
    "    test_output= to_categorical(test_df.status_group.as_matrix())\n",
    "    \n",
    "else:\n",
    "    train_inputs = prepare_inputs(train_df)\n",
    "    test_inputs = prepare_inputs(test_df)\n",
    "    holdout_inputs = prepare_inputs(holdout_df)\n",
    "\n",
    "    train_output= to_categorical(train_df.status_group.as_matrix())\n",
    "    test_output= to_categorical(test_df.status_group.as_matrix())\n",
    "    holdout_output= to_categorical(holdout_df.status_group.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shapes: \n",
      "(32393, 6)\n",
      "(32393, 9)\n",
      "(32393, 7)\n",
      "(32393, 5)\n",
      "(32393, 7)\n",
      "(32393, 6)\n",
      "(32393, 6)\n",
      "(32393, 7)\n",
      "(32393, 21)\n",
      "(32393, 5)\n",
      "(32393, 3)\n",
      "Output shape: (32393, 3)\n"
     ]
    }
   ],
   "source": [
    "print('Input shapes: ')\n",
    "for k in train_inputs.keys():\n",
    "    print(train_inputs[k].shape)\n",
    "    \n",
    "    \n",
    "print('Output shape: {}'.format(train_output.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now let's create the model:\n",
    "    * embedding layers for each categorical input\n",
    "    * dense feature selection layer for all the numeric inputs\n",
    "    * concatenate output of all the layers into  a single latent layer\n",
    "    * dense softmax layer on top of the concatenate layer to do prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "payment_type (InputLayer)        (None, 7)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "management_group (InputLayer)    (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "quality_group (InputLayer)       (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "region (InputLayer)              (None, 21)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "basin (InputLayer)               (None, 9)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "extraction_type_class (InputLaye (None, 7)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "quantity_group (InputLayer)      (None, 5)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "waterpoint_type_group (InputLaye (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "source_type (InputLayer)         (None, 7)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "source_class (InputLayer)        (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "payment_type_embed (Embedding)   (None, 7, 7)          49          payment_type[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "management_group_embed (Embeddin (None, 5, 5)          25          management_group[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "quality_group_embed (Embedding)  (None, 6, 6)          36          quality_group[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "region_embed (Embedding)         (None, 21, 21)        441         region[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "basin_embed (Embedding)          (None, 9, 9)          81          basin[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "extraction_type_class_embed (Emb (None, 7, 7)          49          extraction_type_class[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "quantity_group_embed (Embedding) (None, 5, 5)          25          quantity_group[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "waterpoint_type_group_embed (Emb (None, 6, 6)          36          waterpoint_type_group[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "source_type_embed (Embedding)    (None, 7, 7)          49          source_type[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "source_class_embed (Embedding)   (None, 3, 3)          9           source_class[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "continuous (InputLayer)          (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)             (None, 49)            0           payment_type_embed[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)             (None, 25)            0           management_group_embed[0][0]     \n",
      "____________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)             (None, 36)            0           quality_group_embed[0][0]        \n",
      "____________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)             (None, 441)           0           region_embed[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)             (None, 81)            0           basin_embed[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "flatten_16 (Flatten)             (None, 49)            0           extraction_type_class_embed[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "flatten_17 (Flatten)             (None, 25)            0           quantity_group_embed[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)             (None, 36)            0           waterpoint_type_group_embed[0][0]\n",
      "____________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)             (None, 49)            0           source_type_embed[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)             (None, 9)             0           source_class_embed[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "continuous_dense (Dense)         (None, 32)            224         continuous[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 832)           0           flatten_11[0][0]                 \n",
      "                                                                   flatten_12[0][0]                 \n",
      "                                                                   flatten_13[0][0]                 \n",
      "                                                                   flatten_14[0][0]                 \n",
      "                                                                   flatten_15[0][0]                 \n",
      "                                                                   flatten_16[0][0]                 \n",
      "                                                                   flatten_17[0][0]                 \n",
      "                                                                   flatten_18[0][0]                 \n",
      "                                                                   flatten_19[0][0]                 \n",
      "                                                                   flatten_20[0][0]                 \n",
      "                                                                   continuous_dense[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 832)           0           concatenate_2[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 15)            12495       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "decision (Dense)                 (None, 3)             48          dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 13,567\n",
      "Trainable params: 13,567\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "from keras import layers as L\n",
    "\n",
    "input_layers = []\n",
    "input_name_orders = []\n",
    "concat_layers = []\n",
    "for k in selected_features_categorical:\n",
    "    input_layers.append(L.Input(shape=(train_inputs[k].shape[-1],),name=k))\n",
    "    embed = L.Embedding(input_dim=train_inputs[k].shape[-1], \n",
    "                    output_dim=train_inputs[k].shape[-1],name='{}_embed'.format(k))(input_layers[-1])\n",
    "    embed = L.Flatten()(embed)\n",
    "    concat_layers.append(embed)\n",
    "\n",
    "    input_name_orders.append(k)\n",
    "    \n",
    "input_layers.append(L.Input(shape=(train_inputs['continuous'].shape[-1],),name='continuous'))\n",
    "input_name_orders.append('continuous')\n",
    "concat_layers.append(L.Dense(32,name='continuous_dense', activation='sigmoid')(input_layers[-1]))\n",
    "\n",
    "latent = L.concatenate(concat_layers)\n",
    "latent = L.Dropout(0.5)(latent)\n",
    "latent = L.Dense(15,activation='sigmoid')(latent)\n",
    "output = L.Dense(train_output.shape[-1], activation='softmax', name='decision')(latent)\n",
    "\n",
    "model = Model(inputs=input_layers,outputs=output, name = 'neural_embedder')\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32393 samples, validate on 10798 samples\n",
      "Epoch 1/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2515 - acc: 0.6978 - val_loss: 0.7187 - val_acc: 0.6908\n",
      "Epoch 2/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2473 - acc: 0.6869 - val_loss: 0.7176 - val_acc: 0.6904\n",
      "Epoch 3/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2483 - acc: 0.6828 - val_loss: 0.7132 - val_acc: 0.6915\n",
      "Epoch 4/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2479 - acc: 0.6829 - val_loss: 0.7117 - val_acc: 0.7033\n",
      "Epoch 5/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2480 - acc: 0.6853 - val_loss: 0.7200 - val_acc: 0.6878\n",
      "Epoch 6/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2480 - acc: 0.6823 - val_loss: 0.7082 - val_acc: 0.6873\n",
      "Epoch 7/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2487 - acc: 0.6817 - val_loss: 0.7091 - val_acc: 0.6902\n",
      "Epoch 8/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2492 - acc: 0.6776 - val_loss: 0.7262 - val_acc: 0.6766\n",
      "Epoch 9/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2468 - acc: 0.6835 - val_loss: 0.7215 - val_acc: 0.6792\n",
      "Epoch 10/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2488 - acc: 0.6823 - val_loss: 0.7332 - val_acc: 0.6839\n",
      "Epoch 11/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2507 - acc: 0.6847 - val_loss: 0.7354 - val_acc: 0.6899\n",
      "Epoch 12/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2528 - acc: 0.6828 - val_loss: 0.7259 - val_acc: 0.6909\n",
      "Epoch 13/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2503 - acc: 0.6805 - val_loss: 0.7111 - val_acc: 0.6999\n",
      "Epoch 14/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2501 - acc: 0.6806 - val_loss: 0.7213 - val_acc: 0.6923\n",
      "Epoch 15/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2486 - acc: 0.6834 - val_loss: 0.7179 - val_acc: 0.6810\n",
      "Epoch 16/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2506 - acc: 0.6724 - val_loss: 0.7177 - val_acc: 0.6885\n",
      "Epoch 17/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2502 - acc: 0.6853 - val_loss: 0.7195 - val_acc: 0.6900\n",
      "Epoch 18/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2500 - acc: 0.6846 - val_loss: 0.7285 - val_acc: 0.6936\n",
      "Epoch 19/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2499 - acc: 0.6805 - val_loss: 0.7194 - val_acc: 0.6872\n",
      "Epoch 20/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2489 - acc: 0.6812 - val_loss: 0.7287 - val_acc: 0.6862\n",
      "Epoch 21/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2499 - acc: 0.6811 - val_loss: 0.7148 - val_acc: 0.6965\n",
      "Epoch 22/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2493 - acc: 0.6805 - val_loss: 0.7267 - val_acc: 0.6886\n",
      "Epoch 23/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2484 - acc: 0.6789 - val_loss: 0.7232 - val_acc: 0.6883\n",
      "Epoch 24/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2484 - acc: 0.6835 - val_loss: 0.7124 - val_acc: 0.6936\n",
      "Epoch 25/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2500 - acc: 0.6830 - val_loss: 0.7259 - val_acc: 0.6886\n",
      "Epoch 26/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2502 - acc: 0.6811 - val_loss: 0.7266 - val_acc: 0.6857\n",
      "Epoch 27/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2497 - acc: 0.6880 - val_loss: 0.7198 - val_acc: 0.6911\n",
      "Epoch 28/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2487 - acc: 0.6839 - val_loss: 0.7234 - val_acc: 0.6887\n",
      "Epoch 29/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2487 - acc: 0.6785 - val_loss: 0.7244 - val_acc: 0.6848\n",
      "Epoch 30/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2482 - acc: 0.6809 - val_loss: 0.7197 - val_acc: 0.6859\n",
      "Epoch 31/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2491 - acc: 0.6768 - val_loss: 0.7173 - val_acc: 0.6954\n",
      "Epoch 32/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2483 - acc: 0.6773 - val_loss: 0.7192 - val_acc: 0.6891\n",
      "Epoch 33/5000\n",
      "32393/32393 [==============================] - 2s - loss: 0.2485 - acc: 0.6822 - val_loss: 0.7108 - val_acc: 0.6972\n",
      "Epoch 34/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2513 - acc: 0.6866 - val_loss: 0.7396 - val_acc: 0.6865\n",
      "Epoch 35/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2514 - acc: 0.6782 - val_loss: 0.7235 - val_acc: 0.6856\n",
      "Epoch 36/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2486 - acc: 0.6776 - val_loss: 0.7187 - val_acc: 0.6849\n",
      "Epoch 37/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2489 - acc: 0.6820 - val_loss: 0.7105 - val_acc: 0.6982\n",
      "Epoch 38/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2494 - acc: 0.6785 - val_loss: 0.7110 - val_acc: 0.6949\n",
      "Epoch 39/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2495 - acc: 0.6798 - val_loss: 0.7253 - val_acc: 0.6807\n",
      "Epoch 40/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2496 - acc: 0.6762 - val_loss: 0.7083 - val_acc: 0.6972\n",
      "Epoch 41/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2492 - acc: 0.6818 - val_loss: 0.7216 - val_acc: 0.6878\n",
      "Epoch 42/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2492 - acc: 0.6776 - val_loss: 0.7310 - val_acc: 0.6848\n",
      "Epoch 43/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2493 - acc: 0.6745 - val_loss: 0.7371 - val_acc: 0.6755\n",
      "Epoch 44/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2499 - acc: 0.6658 - val_loss: 0.7225 - val_acc: 0.6774\n",
      "Epoch 45/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2497 - acc: 0.6737 - val_loss: 0.7188 - val_acc: 0.6872\n",
      "Epoch 46/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2481 - acc: 0.6772 - val_loss: 0.7177 - val_acc: 0.6918\n",
      "Epoch 47/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2498 - acc: 0.6759 - val_loss: 0.7339 - val_acc: 0.6774\n",
      "Epoch 48/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2495 - acc: 0.6740 - val_loss: 0.7261 - val_acc: 0.6924\n",
      "Epoch 49/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2490 - acc: 0.6809 - val_loss: 0.7109 - val_acc: 0.7030\n",
      "Epoch 50/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2510 - acc: 0.6858 - val_loss: 0.7225 - val_acc: 0.6968\n",
      "Epoch 51/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2489 - acc: 0.6788 - val_loss: 0.7253 - val_acc: 0.6863\n",
      "Epoch 52/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2491 - acc: 0.6780 - val_loss: 0.7110 - val_acc: 0.6932\n",
      "Epoch 53/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2481 - acc: 0.6808 - val_loss: 0.7239 - val_acc: 0.6889\n",
      "Epoch 54/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2492 - acc: 0.6777 - val_loss: 0.7136 - val_acc: 0.6906\n",
      "Epoch 55/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2484 - acc: 0.6797 - val_loss: 0.7173 - val_acc: 0.6944\n",
      "Epoch 56/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2477 - acc: 0.6790 - val_loss: 0.7133 - val_acc: 0.6903\n",
      "Epoch 57/5000\n",
      "32393/32393 [==============================] - 1s - loss: 0.2485 - acc: 0.6815 - val_loss: 0.7340 - val_acc: 0.6862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14259cc50>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard\n",
    "callbacks = [EarlyStopping(patience=50)]\n",
    "\n",
    "\n",
    "class_weights = {}\n",
    "for i in [0,1,2]:\n",
    "    class_weights[i] = np.square(1-(np.sum(np.argmax(train_output,-1) == i)/len(train_output)))\n",
    "    \n",
    "model.fit(x=[train_inputs[k] for k in input_name_orders],y=train_output,epochs=5000,\n",
    "          validation_data=([test_inputs[k] for k in input_name_orders],test_output),\n",
    "          callbacks=callbacks,batch_size=64\n",
    "          ,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7332    0  538]\n",
      " [ 861    0  148]\n",
      " [2279    0 3239]]\n",
      "Kappa:  0.4662549916391652\n",
      "Acc:  0.7342501910120164\n"
     ]
    }
   ],
   "source": [
    "holdout_pred = np.argmax(model.predict(holdout_inputs),-1)\n",
    "holdout_ref = np.argmax(holdout_output,-1)\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score, confusion_matrix\n",
    "print(confusion_matrix(holdout_ref, holdout_pred))\n",
    "print('Kappa: ', cohen_kappa_score(holdout_ref, holdout_pred))\n",
    "print('Acc: ', accuracy_score(holdout_ref, holdout_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
